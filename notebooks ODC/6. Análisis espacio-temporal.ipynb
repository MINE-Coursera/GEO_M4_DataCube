{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/DonAurelio/open-datacube-bac-training/main/docs/banner.png\" alt=\"Deparatemento de Ingeniería de Sistemas y Computación, Universidad de los Andes\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Análisis espacio temporal - Aplicación de algoritmos para el análisis temporal\n",
    "\n",
    "**Introducción**\n",
    "\n",
    "Los compuestos temporales reducen la incidencia de las nubes en imágenes de satélite. Para ello se realiza un proceso de selección de pixeles en una serie de tiempo para una imagen. Como resultado del proceso de selección, se obtiene una imagen o composición que contiene pixeles de diferentes periodos de tiempo. Estos píxeles son seleccionados mediante la aplicación de un criterio de selección de pixeles. Algunos métodos de selección de píxeles conocidos son: Most Recent / Least Recent Pixel, Maximum Value Composite (MVC), Median Composite, Geomedian Composite, Best Pixel, entre otros. \n",
    "\n",
    "En el presente notebook exploraremos uno de los compuestos mas conocidos, el compuesto de medianas y también haremos un ejercicio sencillo de detección de cambio\n",
    "\n",
    "**Precondiciones - Actividad previa**\n",
    "\n",
    "1. Tener dos imágenes en el cubo - Ver notebooks 1 y 2\n",
    "2. Haber realizado las actividades de los notebooks 3, 4 y 5\n",
    "\n",
    "**Contenido**\n",
    "\n",
    "1. Importar librerías\n",
    "2. Definición del área de estudio y consulta de las imágenes\n",
    "3. Cálculo del compuesto de medianas\n",
    "4. Detección de cambio\n",
    "5. Guardar resultados de análisis en formato netcdf y en tiff\n",
    "\n",
    "**Nota importante:** Este notebook requiere ya de mucha memoria del computador. En caso de presentarse errores de memoria tome las siguientes acciones:\n",
    "- Reinicie el Kernel\n",
    "- En las celdas que dibujan las imágenes, quite los parámetros `size` y `aspect`. eso hace que la visualización de la respuesta sea más pequeña, que consuma menos memoria y que sea más rápida la ejecución de las celdas\n",
    "- Disminuya el tamaño de la zona de estudio, cambiando el valor de la variable buffer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar librerías\n",
    "___\n",
    "En esta sección se importan las librerías cuya funcionalidades particulares son requeridas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# las funcionalidades del open data cube son accedidas \n",
    "# por medio de la librería datacube\n",
    "import datacube\n",
    "\n",
    "# Librería para cálculo en matrices\n",
    "import numpy as np\n",
    "\n",
    "# Manipulación de datasets\n",
    "import xarray as xr\n",
    "\n",
    "# Manipulación de datos raster\n",
    "import rasterio\n",
    "\n",
    "# Librería usada para la carga de polígonos\n",
    "import geopandas as gpd\n",
    "\n",
    "# Librería usada para visualización de datos\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Desactiva los warnings en el notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definición del área de estudio y consulta de las imágenes\n",
    "___\n",
    "Los coordenadas del punto a seleccionar pueden ser obtenidas a través de herramientas GIS como Google maps. Este punto debe estar comprendido en el área que desea estudiar. El punto definido es empleado para la generación de un cuadrado que finalmente será usado para consultar el área de estudio. La variable `buffer` permite ampliar o disminuir las dimensiones del cuadrado. Lo anterior es equivalente a disminuir o ampliar el área de estudio a consultar en el open data cube.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/DonAurelio/open-datacube-bac-training/main/docs/latlong_buffer.png\" alt=\"Definición área de estudio\" width=\"20%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de las coordenadas del punto\n",
    "central_lat = 5.547964746532565\n",
    "central_lon =  -72.9284962779124\n",
    "\n",
    "# Aumento del aŕea del cuadrado para \"EPSG:4326\" (WGS84 - Unidades en grados)\n",
    "#  0.1 grados que corresponden a 11.1 kilómetros alrededor del punto de interés\n",
    "buffer = 0.1\n",
    "\n",
    "# Calculo del cuadro delimitador (bounding box) para el área de estudio\n",
    "set_study_area_lat = (central_lat - buffer, central_lat + buffer)\n",
    "set_study_area_lon = (central_lon - buffer, central_lon + buffer)\n",
    "\n",
    "print(f'    latitude={set_study_area_lat},')\n",
    "print(f'    longitude={set_study_area_lon},')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ahora recuperamos las imágenes que tenga el cubo y que contienen el área de interés**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"MOOC GEO\")\n",
    "\n",
    "dataset = dc.load(\n",
    "    product=\"s2_sen2cor_ard_granule_EO3\",\n",
    "    latitude=(5.447964746532565, 5.647964746532565),\n",
    "    longitude=(-73.0284962779124, -72.82849627791241),\n",
    "    time=('2021-01-01', '2021-02-01'),\n",
    "    measurements=[\"red\",\"blue\",\"green\",\"nir\",\"swir1\",\"swir2\",\"scl\"],\n",
    "    crs=\"EPSG:4326\",\n",
    "    output_crs=\"EPSG:4326\",\n",
    "    resolution=(-0.00008983111,0.00008971023)\n",
    ")\n",
    "\n",
    "# Ver el resultado de la consulta, en el formato del cubo\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**También queremos ver las imágenes recuperadas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = dataset[[\"red\",\"green\",\"blue\"]].to_array(dim='color')\n",
    "rgb = rgb.transpose(*(rgb.dims[1:]+rgb.dims[:1]))  # make 'color' the last dimension\n",
    "img = rgb.plot.imshow(col='time',col_wrap=2,add_colorbar=False,vmin=0,vmax=1200, size = 5, aspect=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cálculo del compuesto de medianas\n",
    "___\n",
    "El compuesto de medianas (Median Composite), es precisamente el cálculo de la mediana  de  cada  píxel  en  una  serie  de  tiempo. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/DonAurelio/open-datacube-bac-training/main/docs/composite.png\" alt=\"Compuesto de medianas\" width=\"60%\">\n",
    "\n",
    "El cálculo del compuesto de medianas comprende dos pasos: \n",
    "\n",
    "1. **Aplicación de la máscara de nubes**\n",
    "2. **Generación del compuesto**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones auxiliares para el cálculo del compuesto de medianas\n",
    "Las siguientes son algunas funciones que ayudan a generar la máscara de nubes, apoyadas en la banda de calidad de Sentinel-2, que ya veremos más en detalle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_bits(land_cover_endcoding, data_array, cover_type):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Unpack bits for end of ls7 and ls8 functions \n",
    "    -----\n",
    "    Input:\n",
    "        land_cover_encoding(dict hash table) land cover endcoding provided by ls7 or ls8\n",
    "        data_array( xarray DataArray)\n",
    "        cover_type(String) type of cover\n",
    "    Output:\n",
    "        unpacked DataArray\n",
    "    \"\"\"\n",
    "    data = data_array.data\n",
    "    if isinstance(data, np.ndarray):\n",
    "        boolean_mask = np.isin(data, land_cover_endcoding[cover_type]) \n",
    "    elif isinstance(data, dask.array.core.Array):\n",
    "        boolean_mask = dask.array.isin(data, land_cover_endcoding[cover_type])\n",
    "    return xr.DataArray(boolean_mask.astype(bool),\n",
    "                        coords = data_array.coords,\n",
    "                        dims = data_array.dims,\n",
    "                        name = cover_type + \"_mask\",\n",
    "                        attrs = data_array.attrs)\n",
    "\n",
    "def s2_unpack_qa(data_array , cover_type):\n",
    "\n",
    "    land_cover_endcoding = dict( \n",
    "        no_data                 =[0],\n",
    "        saturated_or_defective  =[1],\n",
    "        dark_area               =[2],\n",
    "        cloud_shadow            =[3],\n",
    "        vegetation              =[4],\n",
    "        not_vegetated           =[5],\n",
    "        water                   =[6],\n",
    "        unclassified            =[7],\n",
    "        cloud_medium_prob       =[8],\n",
    "        cloud_high_prob         =[9],\n",
    "        thin_cirrus             =[10],\n",
    "        snow                    =[11]\n",
    "    )\n",
    "    return unpack_bits(land_cover_endcoding, data_array, cover_type)\n",
    "\n",
    "def qa_clean_mask(dataset, platform, cover_types=['vegetation', 'not_vegetated']):\n",
    "    \"\"\"\n",
    "    Returns a clean_mask for `dataset` that masks out various types of terrain cover using the\n",
    "    Landsat pixel_qa band. Note that Landsat masks specify what to keep, not what to remove.\n",
    "    This means that using `cover_types=['clear', 'water']` should keep only clear land and water.\n",
    "\n",
    "    See \"pixel_qa band\" here: https://landsat.usgs.gov/landsat-surface-reflectance-quality-assessment\n",
    "    and Section 7 here: https://landsat.usgs.gov/sites/default/files/documents/lasrc_product_guide.pdf.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: xarray.Dataset\n",
    "        An xarray (usually produced by `datacube.load()`) that contains a `pixel_qa` data\n",
    "        variable.\n",
    "    platform: str\n",
    "        A string denoting the platform to be used. Can be \"LANDSAT_5\", \"LANDSAT_7\", or\n",
    "        \"LANDSAT_8\".\n",
    "    cover_types: list\n",
    "        A list of the cover types to include. Adding a cover type allows it to remain in the masked data.\n",
    "        Cover types for all Landsat platforms include:\n",
    "        ['fill', 'clear', 'water', 'shadow', 'snow', 'cloud', 'low_conf_cl', 'med_conf_cl', 'high_conf_cl'].\n",
    "\n",
    "        'fill' removes \"no_data\" values, which indicates an absense of data. This value is -9999 for Landsat platforms.\n",
    "        Generally, don't use 'fill'.\n",
    "        'clear' allows only clear terrain. 'water' allows only water. 'shadow' allows only cloud shadows.\n",
    "        'snow' allows only snow. 'cloud' allows only clouds, but note that it often only selects cloud boundaries.\n",
    "        'low_conf_cl', 'med_conf_cl', and 'high_conf_cl' denote low, medium, and high confidence in cloud coverage.\n",
    "        'low_conf_cl' is useful on its own for only removing clouds, however, 'clear' is usually better suited for this.\n",
    "        'med_conf_cl' is useful in combination with 'low_conf_cl' to allow slightly heavier cloud coverage.\n",
    "        Note that 'med_conf_cl' and 'cloud' are very similar.\n",
    "        'high_conf_cl' is useful in combination with both 'low_conf_cl' and 'med_conf_cl'.\n",
    "\n",
    "        For Landsat 8, there are more cover types: ['low_conf_cir', 'high_conf_cir', 'terrain_occ'].\n",
    "        'low_conf_cir' and 'high_conf_cir' denote low and high confidence in cirrus clouds.\n",
    "        'terrain_occ' allows only occluded terrain.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    clean_mask: xarray.DataArray\n",
    "        An xarray DataArray with the same number and order of coordinates as in `dataset`.\n",
    "    \"\"\"\n",
    "    processing_options = {\n",
    "        \"SENTINEL_2\": s2_unpack_qa\n",
    "    }\n",
    "\n",
    "    clean_mask = None\n",
    "    # Keep all specified cover types (e.g. 'clear', 'water'), so logically or the separate masks.\n",
    "    for i, cover_type in enumerate(cover_types):\n",
    "        cover_type_clean_mask = processing_options[platform](dataset.scl, cover_type)\n",
    "        clean_mask = cover_type_clean_mask if i == 0 else (clean_mask | cover_type_clean_mask)\n",
    "    return clean_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de la máscara de nubes\n",
    "\n",
    "Durante la preparación de las imágenes satelitales Sentinel 2 se genera una banda de calidad llamada `scl`, que es una de las bandas solicitadas al cubo al hacer la consulta del área de estudio. \n",
    "\n",
    "Esta banda de calidad es el resultado de la ejecución de varíos algoritmos especializados de detección de coberturas específicas. \n",
    "\n",
    "Más información sobre estos algoritmos se muestra [aquí](https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm). \n",
    "\n",
    "La tabla a continuación, presenta los valores de la banda de calidad `scl`. Con base en esta banda se aplica el algoritmo de enmascaramiento de nubes (remover las nubes). \n",
    "\n",
    "| Atributo                 | Valor del Píxel |\n",
    "|--------------------------|-----------------|\n",
    "| No Data                  | 0               |\n",
    "| Saturated or defective   | 1               |\n",
    "| Dark area Pixels         | 2               |\n",
    "| Cloud Shadows            | 3               |\n",
    "| Vegetation               | 4               |\n",
    "| Not vegetated            | 5               |\n",
    "| Water                    | 6               |\n",
    "| Unclassified             | 7               |\n",
    "| Cloud Medium probability | 8               |\n",
    "| Cloud High probability   | 9               |\n",
    "| Thin Cirrus              | 10              |\n",
    "| Snow                     | 11              |\n",
    "\n",
    "**Lo primero que haremos es visualizar esta banda, con la clasificación aquí explicada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definición de la paleta de colores\n",
    "cmap = mpl.colors.ListedColormap(\n",
    "    [\n",
    "        '#000000', \n",
    "        '#fe0000',\n",
    "        '#404040', \n",
    "        '#833d0c', \n",
    "        '#00ff01', \n",
    "        '#ffff01', \n",
    "        '#0000cc', \n",
    "        '#757170', \n",
    "        '#aeaaa9', \n",
    "        '#d0ced0', \n",
    "        '#00ccff', \n",
    "        '#ff66ff'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Rango de valores establecidos para cada color\n",
    "bounds = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "# Genera una capa de normalización de los datos basada en los intervalos establecidos en 'bounds'\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Generación de la imagen\n",
    "img = dataset.scl.plot(col='time',col_wrap=2, cmap=cmap, norm=norm, size = 5)\n",
    "\n",
    "#Generación de la leyenda de la imagen, que ayuda a la comprensión de la misma\n",
    "classification_labels = [\n",
    "    'no_data',\n",
    "    'saturated_defective',\n",
    "    'dark_area_pixels',\n",
    "    'cloud_shadows',\n",
    "    'vegetation',\n",
    "    'not_vegetated',\n",
    "    'water',\n",
    "    'unclassified',\n",
    "    'cloud_medium_probability',\n",
    "    'Cloud_high_probability',\n",
    "    'thin_cirrus',\n",
    "    'snow'\n",
    "]\n",
    "\n",
    "# Permite centrar las etiquetas de los colores en el colorbar\n",
    "classification_labels_ticks = np.linspace(0.5, 11.5, num=12)\n",
    "\n",
    "# Configuración de las etiquetas de la barra de colores\n",
    "img.cbar.set_ticklabels(classification_labels)\n",
    "img.cbar.set_ticks(classification_labels_ticks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro caso particular, estamos interesados en los píxeles que presentan probabilidades altas de ser vegetación. Por lo tanto en la máscara de nubes indicamos que deseamos conservar estos píxeles (`qa_clean_mask(dataset,platform='SENTINEL_2',cover_types=['vegetation'])`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación máscara para valores inválidos\n",
    "mask_nan = ~np.isnan(dataset)              # Deja los píxeles que tienen valor diferente a NaN\n",
    "mask_inf = ~np.isinf(dataset)              # Deja los píxeles que tienen valor diferente a +/- inifinito\n",
    "\n",
    "# Generación máscara de nubes\n",
    "clean_mask = qa_clean_mask(dataset,platform='SENTINEL_2',cover_types=['vegetation'])\n",
    "\n",
    "# La máscara con el formato del cubo\n",
    "clean_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que la máscara, para cada imagen, es una matriz de valores booleanos (True, False) que indica, para cada pixel, si en esa posición hay un valor válido para análisis.\n",
    "\n",
    "**Miremos también la imagen de la máscara de vegetación**\n",
    "\n",
    "Para cada una de las imágenes, obtenemos en amarillo los píxeles que son válidos para análisis de vegetación y en morado los que no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de la imagen de la máscara\n",
    "img = clean_mask.plot(col='time',col_wrap=2, add_colorbar=False, size = 5, aspect = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de la máscara de nubes\n",
    "clean_dataset = dataset.where(clean_mask & mask_nan & mask_inf)\n",
    "\n",
    "# Visualización en verdadero color de las imágenes, a las cuales se les eliminó, \n",
    "# por medio de la máscara: los píxeles inválidos y los que no están clasificados como vegetación\n",
    "rgb = clean_dataset[[\"red\",\"green\",\"blue\"]].to_array(dim='color')\n",
    "rgb = rgb.transpose(*(rgb.dims[1:]+rgb.dims[:1]))  # make 'color' the last dimension\n",
    "img = rgb.plot.imshow(col='time',col_wrap=2,add_colorbar=False,vmin=0, vmax=1200, size=5, aspect = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo del compuesto de medianas \n",
    "Ya teniendo las dos imágenes limpias, podemos proceder al cálculos de las medianas.\n",
    "\n",
    "Primero vemos el resultado en la estructura de datos y luego la visualizamos en verdadero color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_composite = clean_dataset.median('time', skipna=True)\n",
    "median_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = median_composite[[\"red\",\"green\",\"blue\"]].to_array(dim='color')\n",
    "rgb = rgb.transpose(*(rgb.dims[1:]+rgb.dims[:1]))  # make 'color' the last dimension\n",
    "img = rgb.plot.imshow(add_colorbar=False,vmin=0,vmax=1200,figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "En el resultado todavía hay mucha cobertura de nubes. Esto es debido a que sólo estamos utilizando dos imágenes...\n",
    "\n",
    "Para lograr una imagen sin nubes, es necesario procesar decenas de imágenes del mismo sitio y componerlas, tomando los píxeles que tienen valores válidos. Esto se llama armar un mosaico de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Detección de cambio\n",
    "___\n",
    "Una de las preguntas más frecuentes es saber qué cambió en una región entre dos momentos del tiempo. Hay muchas formas de responder esta pregunta, que no es nada evidente...\n",
    "\n",
    "En este ejercicio vamos a responder una pregunta más sencilla: ¿Dónde hubo cambios del NVDI entre estos dos momentos del tiempo?\n",
    "\n",
    "Y la forma de responderla es trabajando sobre las imágenes limpias y simplemente restando el NVDI de una imagen del de la otra. \n",
    "\n",
    "Resultados cercanos a 0 (en gris) se interpretan como que no hubo cambio y valores lejanos de 0 se interpretan como que algo cambió (en rojo y azul)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo del NDVI de las imágenes limpias\n",
    "clean_dataset['ndvi'] = (clean_dataset.nir - clean_dataset.red) / (clean_dataset.nir + clean_dataset.red)\n",
    "\n",
    "# Cálculo de la diferencia del NDVI de las dos imágenes\n",
    "ndvi_diff = clean_dataset['ndvi'].isel(time = 1) - clean_dataset['ndvi'].isel (time = 0)\n",
    "ndvi_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización del resultado\n",
    "\n",
    "# Definición de la paleta de colores\n",
    "cmap = mpl.colors.ListedColormap(\n",
    "    [\n",
    "        '#0000FF',\n",
    "        '#f1c40f',\n",
    "        '#D8D8D8',\n",
    "        '#b03a2e', \n",
    "        '#3ADF00' \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Rango de valores establecidos para cada color\n",
    "bounds = [-1,-0.6,-0.1,0.1,0.6,1]\n",
    "\n",
    "# Genera una capa de normalización de los datos basada en los intervalos establecidos en 'bounds'\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "#Generación de la imagen\n",
    "ndvi_diff.plot (size=10, aspect=1, cmap = cmap, norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Aunque este es un resultado relativamente simple y que necesita más elaboración para la resolución de algún problema particular, ilustra la potencia y versatibilidad de trabajar con el cubo de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Guardar resultados de análisis en formato netcdf y en tiff\n",
    "___\n",
    "Al igual que antes, podemos guardar los resultados para análisis posteriores con herramientas SIG.\n",
    "\n",
    "Estas celdas están programadas para guardar los resultados del cálculo de medianas, pero pueden guardar cualquiera (o todos) los resultados de los ejercicios de este notebook\n",
    "\n",
    "### Guardar resultados de análisis en un archivo .nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_composite.to_netcdf('Salidas/mediana.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar resultados de análisis en formato geotiff\n",
    "___\n",
    "Funciones requeridas para guardar información en geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Las funciones mostradas a continuación fueron tomadas de \n",
    "https://github.com/ceos-seo/data_cube_notebooks\n",
    "\"\"\"\n",
    "\n",
    "def _get_transform_from_xr(data, x_coord='longitude', y_coord='latitude'):\n",
    "    \"\"\"Create a geotransform from an xarray.Dataset or xarray.DataArray.\n",
    "    \"\"\"\n",
    "\n",
    "    from rasterio.transform import from_bounds\n",
    "    geotransform = from_bounds(data[x_coord][0], data[y_coord][-1],\n",
    "                               data[x_coord][-1], data[y_coord][0],\n",
    "                               len(data[x_coord]), len(data[y_coord]))\n",
    "    return geotransform\n",
    "\n",
    "def write_geotiff_from_xr(tif_path, data, bands=None, no_data=-9999, crs=\"EPSG:4326\",\n",
    "                          x_coord='longitude', y_coord='latitude'):\n",
    "    \"\"\"\n",
    "    NOTE: Instead of this function, please use `import_export.export_xarray_to_geotiff()`.\n",
    "    Export a GeoTIFF from an `xarray.Dataset`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    tif_path: string\n",
    "        The path to write the GeoTIFF file to. You should include the file extension.\n",
    "    data: xarray.Dataset or xarray.DataArray\n",
    "    bands: list of string\n",
    "        The bands to write - in the order they should be written.\n",
    "        Ignored if `data` is an `xarray.DataArray`.\n",
    "    no_data: int\n",
    "        The nodata value.\n",
    "    crs: string\n",
    "        The CRS of the output.\n",
    "    x_coord, y_coord: string\n",
    "        The string names of the x and y dimensions.\n",
    "    \"\"\"\n",
    "    if isinstance(data, xr.DataArray):\n",
    "        height, width = data.sizes[y_coord], data.sizes[x_coord]\n",
    "        count, dtype = 1, data.dtype\n",
    "    else:\n",
    "        if bands is None:\n",
    "            bands = list(data.data_vars.keys())\n",
    "        else:\n",
    "            assrt_msg_begin = \"The `data` parameter is an `xarray.Dataset`. \"\n",
    "            assert isinstance(bands, list), assrt_msg_begin + \"Bands must be a list of strings.\"\n",
    "            assert len(bands) > 0 and isinstance(bands[0], str), assrt_msg_begin + \"You must supply at least one band.\"\n",
    "        height, width = data.dims[y_coord], data.dims[x_coord]\n",
    "        count, dtype = len(bands), data[bands[0]].dtype\n",
    "    with rasterio.open(\n",
    "            tif_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=height,\n",
    "            width=width,\n",
    "            count=count,\n",
    "            dtype=dtype,\n",
    "            crs=crs,\n",
    "            transform=_get_transform_from_xr(data, x_coord=x_coord, y_coord=y_coord),\n",
    "            nodata=no_data) as dst:\n",
    "        if isinstance(data, xr.DataArray):\n",
    "            dst.write(data.values, 1)\n",
    "        else:\n",
    "            for index, band in enumerate(bands):\n",
    "                dst.write(data[band].values, index + 1)\n",
    "    dst.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar resultados de análisis en un archivo .tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_geotiff_from_xr(\n",
    "    tif_path='Salidas/mediana.tif', \n",
    "    data=median_composite, \n",
    "    bands=['red','green','blue',],      # El orden de las bandas es importante para visualizar la imagen en una herramienta GIS\n",
    "    no_data=-9999, \n",
    "    crs=\"EPSG:4326\",\n",
    "    x_coord='longitude',\n",
    "    y_coord='latitude'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
